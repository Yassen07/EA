{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from multiprocessing import Pool\n",
    "from functools import reduce\n",
    "import concurrent.futures as futures\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "# loading dataset\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "def leaky_relu(x, a=0.01):\n",
    "    return np.maximum(a*x, x)\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "    \n",
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    return A\n",
    "class Layer:\n",
    "    def __init__(self, input_units, output_units, activation_function=None):\n",
    "#         random_array = np.random.uniform(low, high, size=(input_units, output_units))\n",
    "        self.W = np.random.uniform(-1, 1, size=(input_units, output_units))\n",
    "        self.b = np.random.uniform(-1, 1, size=(output_units))\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        linear_output = np.dot(inputs, self.W) + self.b\n",
    "        if self.activation_function is None:\n",
    "            return linear_output\n",
    "        else:\n",
    "            return self.activation_function(linear_output)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.model_weights = []\n",
    "        self.model_biases = []\n",
    "        self.accuracy = None\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.model_weights.append(layer.W)\n",
    "        self.model_biases.append(layer.b)\n",
    "\n",
    "    def predict_prob(self, input_data):\n",
    "        return [reduce(lambda output, layer: layer.forward(output), self.layers, data) for data in input_data]\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        prob_predictions = self.predict_prob(input_data)\n",
    "        return [np.argmax(prediction) for prediction in prob_predictions]\n",
    "\n",
    "\n",
    "    def print_architecture(self):\n",
    "        print(\"Model Architecture:\")\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            activation = layer.activation_function.__name__ if layer.activation_function else \"None\"\n",
    "            print(f\"Layer {i+1}: Units={layer.W.shape[1]}, Activation={activation}\")\n",
    "\n",
    "    def print_weights(self):\n",
    "        print(\"Model Weights:\")\n",
    "        for i, w in enumerate(self.model_weights):\n",
    "            print(f\"Layer {i+1} shape : {w.shape} weights:\")\n",
    "            print(w)\n",
    "            \n",
    "    def set_accuracy(self, input_data, true_labels):\n",
    "        predicted_labels = self.predict(input_data)\n",
    "        self.accuracy= accuracy_score(true_labels,predicted_labels)*100\n",
    "    def get_accuracy(self):\n",
    "        return self.accuracy\n",
    "def gen_individual():\n",
    "    neural_network = NeuralNetwork()\n",
    "    first_layer = Layer(4, 16, leaky_relu)\n",
    "    second_layer = Layer(16, 16, leaky_relu)\n",
    "    last_layer = Layer(16, 3, softmax)\n",
    "    neural_network.add(first_layer)\n",
    "    neural_network.add(second_layer)\n",
    "    neural_network.add(last_layer)\n",
    "    return neural_network\n",
    "def euclidean_distance(ind1, ind2):\n",
    "    total_distance = 0\n",
    "    for w1, w2, b1, b2 in zip(ind1.model_weights, ind2.model_weights, ind1.model_biases, ind2.model_biases):\n",
    "        total_distance += np.sum((w1 - w2) ** 2)\n",
    "        total_distance += np.sum((b1 - b2) ** 2)\n",
    "    return np.sqrt(total_distance)\n",
    "def fitness(individual):\n",
    "    individual.set_accuracy(x, y)\n",
    "    accuracy = individual.get_accuracy()\n",
    "    return accuracy\n",
    "def shared_fitness(individual, population, sigma_share=20.5, alpha=1.0):\n",
    "    distances = np.array([euclidean_distance(individual, other) for other in population if individual != other])\n",
    "    sharing_sum = np.sum(1 - (distances[distances < sigma_share] / sigma_share) ** alpha)\n",
    "    raw_fitness = fitness(individual)\n",
    "    adjusted_fitness = raw_fitness / (1 + sharing_sum)\n",
    "    return adjusted_fitness\n",
    "\n",
    "def generate_population(population_size):\n",
    "    population = []\n",
    "    fitnesses = []\n",
    "    for i in range(population_size):\n",
    "        individual = gen_individual()\n",
    "        population.append(individual)\n",
    "        fitnesses.append(fitness(individual))\n",
    "    return population, fitnesses\n",
    "def new_child(p1, p2, p3, target,cr, f):\n",
    "    mutant=gen_individual()\n",
    "    trial=gen_individual()\n",
    "    for i in range(len(mutant.model_weights)):\n",
    "      differencew = f * (p1.model_weights[i] - p2.model_weights[i])\n",
    "      differenceb = f * (p1.model_biases[i] - p2.model_biases[i])\n",
    "      mutant.model_weights[i]= p3.model_weights[i] + differencew\n",
    "      mutant.model_biases[i]= p3.model_biases[i]  + differenceb\n",
    "\n",
    "      for j in range(len(trial.model_weights[i])):\n",
    "        trial.model_weights[i][j]= mutant.model_weights[i][j] if random.random() <= cr else target.model_weights[i][j]\n",
    "      for j in range(len(trial.model_biases[i])):\n",
    "        trial.model_biases[i][j]= mutant.model_biases[i][j] if random.random() <= cr else target.model_biases[i][j]\n",
    "    return trial\n",
    "    \n",
    "def evaluate_target(args):\n",
    "    target, population, f, cr, sigma_share, alpha = args\n",
    "    a, b, c = random.sample(list(population), 3)\n",
    "    trial = new_child(a, b, c, target, cr, f)\n",
    "    trial_acc = shared_fitness(trial, population, sigma_share, alpha)\n",
    "    target_acc = shared_fitness(target, population, sigma_share, alpha)\n",
    "    if trial_acc > target_acc:\n",
    "        result = [trial, trial_acc]\n",
    "    else:\n",
    "        result = [target, target_acc]\n",
    "    return result\n",
    "def differential_evolution(population_size, f=1.5, cr=0.9, max_iters=240, sigma_share=130.0, alpha=1.0, max_stall_iters=10, percentage_to_keep=0.25):\n",
    "    # Initialize history dictionary to store accuracies\n",
    "    history = {\n",
    "        \"best\": [],\n",
    "        \"average\": [],\n",
    "        \"worst\": []\n",
    "    }\n",
    "    population, fitnesses = generate_population(population_size)\n",
    "    best = population[np.argmax(fitnesses)]\n",
    "    best_acc = max(fitnesses)\n",
    "    print(best_acc)\n",
    "    num_iters = 0\n",
    "    stall_iters = 0\n",
    "    while num_iters < max_iters:\n",
    "        with futures.ThreadPoolExecutor(max_workers=12) as executor:\n",
    "            args_list = [(target, population, f, cr, sigma_share, alpha) for target in population]\n",
    "            try:\n",
    "                results = list(executor.map(evaluate_target, args_list))\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                break\n",
    "  \n",
    "        results = np.array(results)\n",
    "        \n",
    "        new_population = results[:,0]\n",
    "        new_fitnesses = results[:,1]\n",
    "\n",
    "\n",
    "\n",
    "        best_index = np.argmax(new_fitnesses)\n",
    "        new_best_acc = new_fitnesses[best_index]\n",
    "\n",
    "        if new_best_acc > best_acc:\n",
    "            best_acc = new_best_acc\n",
    "            best = new_population[best_index]\n",
    "            stall_iters = 0\n",
    "        else:\n",
    "            stall_iters += 1\n",
    "\n",
    "        population = new_population\n",
    "        num_iters += 1\n",
    "        avr=np.mean(new_fitnesses)\n",
    "\n",
    "        # Store accuracies in history dictionary\n",
    "        history[\"best\"].append(best_acc)\n",
    "        history[\"average\"].append(avr)\n",
    "        history[\"worst\"].append(np.min(new_fitnesses))\n",
    "\n",
    "        print(f\"Iteration: {num_iters} -> Best Accuracy: {best_acc:.2f} % -> Average:{avr:.2f} \")\n",
    "\n",
    "        # Restart if best accuracy has not improved for max_stall_iters iterations\n",
    "        if stall_iters == max_stall_iters:\n",
    "            print(f\"Restarting population due to stalling for {max_stall_iters} iterations...\")\n",
    "            sorted_indices = np.argsort(-new_fitnesses)\n",
    "            keep = int(percentage_to_keep*population_size)\n",
    "            new_indx = sorted_indices[:keep]\n",
    "            keep_pop = new_population[new_indx]\n",
    "            population, fitnesses = generate_population(population_size-keep)\n",
    "            # population.append(best)\n",
    "            # fitnesses.append(best_acc)\n",
    "            population = np.concatenate((keep_pop, population))\n",
    "            best = population[np.argmax(fitnesses)]\n",
    "            best_acc = max(fitnesses)\n",
    "            stall_iters = 0\n",
    "\n",
    "    return population, best, best_acc, history\n",
    "def plot_history(history):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for key in history.keys():\n",
    "        fig.add_trace(go.Scatter(x=list(range(1, len(history[key]) + 1)), y=history[key], mode='lines', name=key))\n",
    "\n",
    "    fig.update_layout(title='Evolution of Accuracy',\n",
    "                      xaxis_title='Iteration',\n",
    "                      yaxis_title='Accuracy',\n",
    "                      legend_title='Accuracy Type')\n",
    "\n",
    "    pio.show(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.0\n",
      "Iteration: 1 -> Best Accuracy: 66.00 % -> Average:1.62 \n",
      "Iteration: 2 -> Best Accuracy: 66.00 % -> Average:2.09 \n",
      "Iteration: 3 -> Best Accuracy: 66.00 % -> Average:6.51 \n",
      "Iteration: 4 -> Best Accuracy: 66.67 % -> Average:31.47 \n",
      "Iteration: 5 -> Best Accuracy: 66.67 % -> Average:41.84 \n",
      "Iteration: 6 -> Best Accuracy: 66.67 % -> Average:43.84 \n",
      "Iteration: 7 -> Best Accuracy: 66.67 % -> Average:48.42 \n",
      "Iteration: 8 -> Best Accuracy: 69.33 % -> Average:51.53 \n",
      "Iteration: 9 -> Best Accuracy: 69.33 % -> Average:51.71 \n",
      "Iteration: 10 -> Best Accuracy: 69.33 % -> Average:54.00 \n",
      "Iteration: 11 -> Best Accuracy: 69.33 % -> Average:56.93 \n",
      "Iteration: 12 -> Best Accuracy: 69.33 % -> Average:58.00 \n",
      "Iteration: 13 -> Best Accuracy: 69.33 % -> Average:60.07 \n",
      "Iteration: 14 -> Best Accuracy: 69.33 % -> Average:62.22 \n",
      "Iteration: 15 -> Best Accuracy: 69.33 % -> Average:62.31 \n",
      "Iteration: 16 -> Best Accuracy: 69.33 % -> Average:62.31 \n",
      "Iteration: 17 -> Best Accuracy: 69.33 % -> Average:63.87 \n",
      "Iteration: 18 -> Best Accuracy: 69.33 % -> Average:63.87 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 19 -> Best Accuracy: 84.67 % -> Average:33.68 \n",
      "Iteration: 20 -> Best Accuracy: 84.67 % -> Average:44.86 \n",
      "Iteration: 21 -> Best Accuracy: 84.67 % -> Average:49.27 \n",
      "Iteration: 22 -> Best Accuracy: 95.33 % -> Average:53.31 \n",
      "Iteration: 23 -> Best Accuracy: 95.33 % -> Average:56.53 \n",
      "Iteration: 24 -> Best Accuracy: 95.33 % -> Average:60.62 \n",
      "Iteration: 25 -> Best Accuracy: 95.33 % -> Average:60.93 \n",
      "Iteration: 26 -> Best Accuracy: 95.33 % -> Average:61.96 \n",
      "Iteration: 27 -> Best Accuracy: 95.33 % -> Average:62.22 \n",
      "Iteration: 28 -> Best Accuracy: 95.33 % -> Average:62.22 \n",
      "Iteration: 29 -> Best Accuracy: 95.33 % -> Average:62.22 \n",
      "Iteration: 30 -> Best Accuracy: 95.33 % -> Average:62.93 \n",
      "Iteration: 31 -> Best Accuracy: 95.33 % -> Average:63.89 \n",
      "Iteration: 32 -> Best Accuracy: 95.33 % -> Average:64.07 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 33 -> Best Accuracy: 95.33 % -> Average:41.28 \n",
      "Iteration: 34 -> Best Accuracy: 95.33 % -> Average:56.40 \n",
      "Iteration: 35 -> Best Accuracy: 95.33 % -> Average:60.24 \n",
      "Iteration: 36 -> Best Accuracy: 95.33 % -> Average:61.67 \n",
      "Iteration: 37 -> Best Accuracy: 95.33 % -> Average:63.60 \n",
      "Iteration: 38 -> Best Accuracy: 95.33 % -> Average:67.78 \n",
      "Iteration: 39 -> Best Accuracy: 95.33 % -> Average:69.44 \n",
      "Iteration: 40 -> Best Accuracy: 95.33 % -> Average:70.49 \n",
      "Iteration: 41 -> Best Accuracy: 95.33 % -> Average:70.89 \n",
      "Iteration: 42 -> Best Accuracy: 95.33 % -> Average:71.49 \n",
      "Iteration: 43 -> Best Accuracy: 95.33 % -> Average:72.91 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 44 -> Best Accuracy: 95.33 % -> Average:40.61 \n",
      "Iteration: 45 -> Best Accuracy: 95.33 % -> Average:55.81 \n",
      "Iteration: 46 -> Best Accuracy: 95.33 % -> Average:61.69 \n",
      "Iteration: 47 -> Best Accuracy: 95.33 % -> Average:63.38 \n",
      "Iteration: 48 -> Best Accuracy: 95.33 % -> Average:65.04 \n",
      "Iteration: 49 -> Best Accuracy: 95.33 % -> Average:67.98 \n",
      "Iteration: 50 -> Best Accuracy: 95.33 % -> Average:71.76 \n",
      "Iteration: 51 -> Best Accuracy: 95.33 % -> Average:72.98 \n",
      "Iteration: 52 -> Best Accuracy: 95.33 % -> Average:72.98 \n",
      "Iteration: 53 -> Best Accuracy: 95.33 % -> Average:73.29 \n",
      "Iteration: 54 -> Best Accuracy: 95.33 % -> Average:73.42 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 55 -> Best Accuracy: 95.33 % -> Average:42.88 \n",
      "Iteration: 56 -> Best Accuracy: 95.33 % -> Average:61.69 \n",
      "Iteration: 57 -> Best Accuracy: 95.33 % -> Average:68.91 \n",
      "Iteration: 58 -> Best Accuracy: 95.33 % -> Average:71.62 \n",
      "Iteration: 59 -> Best Accuracy: 95.33 % -> Average:73.84 \n",
      "Iteration: 60 -> Best Accuracy: 95.33 % -> Average:74.69 \n",
      "Iteration: 61 -> Best Accuracy: 95.33 % -> Average:75.84 \n",
      "Iteration: 62 -> Best Accuracy: 95.33 % -> Average:76.11 \n",
      "Iteration: 63 -> Best Accuracy: 95.33 % -> Average:77.58 \n",
      "Iteration: 64 -> Best Accuracy: 95.33 % -> Average:77.80 \n",
      "Iteration: 65 -> Best Accuracy: 95.33 % -> Average:78.31 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 66 -> Best Accuracy: 95.33 % -> Average:48.58 \n",
      "Iteration: 67 -> Best Accuracy: 95.33 % -> Average:61.02 \n",
      "Iteration: 68 -> Best Accuracy: 95.33 % -> Average:65.44 \n",
      "Iteration: 69 -> Best Accuracy: 95.33 % -> Average:68.89 \n",
      "Iteration: 70 -> Best Accuracy: 95.33 % -> Average:73.82 \n",
      "Iteration: 71 -> Best Accuracy: 95.33 % -> Average:73.89 \n",
      "Iteration: 72 -> Best Accuracy: 95.33 % -> Average:75.29 \n",
      "Iteration: 73 -> Best Accuracy: 95.33 % -> Average:75.84 \n",
      "Iteration: 74 -> Best Accuracy: 95.33 % -> Average:76.33 \n",
      "Iteration: 75 -> Best Accuracy: 95.33 % -> Average:77.11 \n",
      "Iteration: 76 -> Best Accuracy: 95.33 % -> Average:77.36 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 77 -> Best Accuracy: 95.33 % -> Average:46.04 \n",
      "Iteration: 78 -> Best Accuracy: 95.33 % -> Average:61.25 \n",
      "Iteration: 79 -> Best Accuracy: 95.33 % -> Average:66.62 \n",
      "Iteration: 80 -> Best Accuracy: 95.33 % -> Average:67.96 \n",
      "Iteration: 81 -> Best Accuracy: 95.33 % -> Average:73.67 \n",
      "Iteration: 82 -> Best Accuracy: 95.33 % -> Average:73.67 \n",
      "Iteration: 83 -> Best Accuracy: 95.33 % -> Average:74.58 \n",
      "Iteration: 84 -> Best Accuracy: 95.33 % -> Average:76.82 \n",
      "Iteration: 85 -> Best Accuracy: 95.33 % -> Average:77.67 \n",
      "Iteration: 86 -> Best Accuracy: 95.33 % -> Average:78.38 \n",
      "Iteration: 87 -> Best Accuracy: 95.33 % -> Average:80.00 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 88 -> Best Accuracy: 95.33 % -> Average:48.92 \n",
      "Iteration: 89 -> Best Accuracy: 95.33 % -> Average:63.00 \n",
      "Iteration: 90 -> Best Accuracy: 95.33 % -> Average:65.76 \n",
      "Iteration: 91 -> Best Accuracy: 95.33 % -> Average:70.64 \n",
      "Iteration: 92 -> Best Accuracy: 95.33 % -> Average:75.38 \n",
      "Iteration: 93 -> Best Accuracy: 95.33 % -> Average:76.36 \n",
      "Iteration: 94 -> Best Accuracy: 95.33 % -> Average:76.60 \n",
      "Iteration: 95 -> Best Accuracy: 95.33 % -> Average:77.80 \n",
      "Iteration: 96 -> Best Accuracy: 95.33 % -> Average:77.91 \n",
      "Iteration: 97 -> Best Accuracy: 95.33 % -> Average:78.27 \n",
      "Iteration: 98 -> Best Accuracy: 95.33 % -> Average:78.87 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 99 -> Best Accuracy: 96.67 % -> Average:47.47 \n",
      "Iteration: 100 -> Best Accuracy: 96.67 % -> Average:65.64 \n",
      "Iteration: 101 -> Best Accuracy: 96.67 % -> Average:70.73 \n",
      "Iteration: 102 -> Best Accuracy: 96.67 % -> Average:75.31 \n",
      "Iteration: 103 -> Best Accuracy: 96.67 % -> Average:76.22 \n",
      "Iteration: 104 -> Best Accuracy: 96.67 % -> Average:78.62 \n",
      "Iteration: 105 -> Best Accuracy: 96.67 % -> Average:79.78 \n",
      "Iteration: 106 -> Best Accuracy: 96.67 % -> Average:81.76 \n",
      "Iteration: 107 -> Best Accuracy: 96.67 % -> Average:82.38 \n",
      "Iteration: 108 -> Best Accuracy: 96.67 % -> Average:84.69 \n",
      "Iteration: 109 -> Best Accuracy: 96.67 % -> Average:85.27 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 110 -> Best Accuracy: 96.67 % -> Average:49.21 \n",
      "Iteration: 111 -> Best Accuracy: 96.67 % -> Average:59.29 \n",
      "Iteration: 112 -> Best Accuracy: 96.67 % -> Average:63.09 \n",
      "Iteration: 113 -> Best Accuracy: 96.67 % -> Average:67.07 \n",
      "Iteration: 114 -> Best Accuracy: 96.67 % -> Average:72.24 \n",
      "Iteration: 115 -> Best Accuracy: 96.67 % -> Average:73.42 \n",
      "Iteration: 116 -> Best Accuracy: 96.67 % -> Average:74.40 \n",
      "Iteration: 117 -> Best Accuracy: 96.67 % -> Average:74.40 \n",
      "Iteration: 118 -> Best Accuracy: 96.67 % -> Average:74.47 \n",
      "Iteration: 119 -> Best Accuracy: 96.67 % -> Average:75.67 \n",
      "Iteration: 120 -> Best Accuracy: 96.67 % -> Average:76.22 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 121 -> Best Accuracy: 96.67 % -> Average:50.53 \n",
      "Iteration: 122 -> Best Accuracy: 96.67 % -> Average:73.13 \n",
      "Iteration: 123 -> Best Accuracy: 96.67 % -> Average:76.69 \n",
      "Iteration: 124 -> Best Accuracy: 96.67 % -> Average:81.20 \n",
      "Iteration: 125 -> Best Accuracy: 96.67 % -> Average:83.07 \n",
      "Iteration: 126 -> Best Accuracy: 96.67 % -> Average:85.40 \n",
      "Iteration: 127 -> Best Accuracy: 96.67 % -> Average:85.82 \n",
      "Iteration: 128 -> Best Accuracy: 96.67 % -> Average:86.80 \n",
      "Iteration: 129 -> Best Accuracy: 96.67 % -> Average:88.47 \n",
      "Iteration: 130 -> Best Accuracy: 96.67 % -> Average:90.18 \n",
      "Iteration: 131 -> Best Accuracy: 96.67 % -> Average:90.69 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 132 -> Best Accuracy: 96.67 % -> Average:41.19 \n",
      "Iteration: 133 -> Best Accuracy: 96.67 % -> Average:68.29 \n",
      "Iteration: 134 -> Best Accuracy: 96.67 % -> Average:72.49 \n",
      "Iteration: 135 -> Best Accuracy: 96.67 % -> Average:76.24 \n",
      "Iteration: 136 -> Best Accuracy: 96.67 % -> Average:78.22 \n",
      "Iteration: 137 -> Best Accuracy: 96.67 % -> Average:79.58 \n",
      "Iteration: 138 -> Best Accuracy: 96.67 % -> Average:81.16 \n",
      "Iteration: 139 -> Best Accuracy: 96.67 % -> Average:82.84 \n",
      "Iteration: 140 -> Best Accuracy: 96.67 % -> Average:84.64 \n",
      "Iteration: 141 -> Best Accuracy: 96.67 % -> Average:85.71 \n",
      "Iteration: 142 -> Best Accuracy: 96.67 % -> Average:86.36 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 143 -> Best Accuracy: 96.67 % -> Average:49.97 \n",
      "Iteration: 144 -> Best Accuracy: 96.67 % -> Average:67.51 \n",
      "Iteration: 145 -> Best Accuracy: 96.67 % -> Average:70.24 \n",
      "Iteration: 146 -> Best Accuracy: 96.67 % -> Average:73.80 \n",
      "Iteration: 147 -> Best Accuracy: 96.67 % -> Average:75.56 \n",
      "Iteration: 148 -> Best Accuracy: 96.67 % -> Average:78.93 \n",
      "Iteration: 149 -> Best Accuracy: 96.67 % -> Average:81.11 \n",
      "Iteration: 150 -> Best Accuracy: 96.67 % -> Average:81.27 \n",
      "Iteration: 151 -> Best Accuracy: 96.67 % -> Average:83.27 \n",
      "Iteration: 152 -> Best Accuracy: 96.67 % -> Average:83.62 \n",
      "Iteration: 153 -> Best Accuracy: 96.67 % -> Average:83.96 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 154 -> Best Accuracy: 96.67 % -> Average:52.01 \n",
      "Iteration: 155 -> Best Accuracy: 96.67 % -> Average:70.47 \n",
      "Iteration: 156 -> Best Accuracy: 96.67 % -> Average:75.31 \n",
      "Iteration: 157 -> Best Accuracy: 96.67 % -> Average:77.98 \n",
      "Iteration: 158 -> Best Accuracy: 96.67 % -> Average:80.82 \n",
      "Iteration: 159 -> Best Accuracy: 96.67 % -> Average:82.09 \n",
      "Iteration: 160 -> Best Accuracy: 96.67 % -> Average:85.07 \n",
      "Iteration: 161 -> Best Accuracy: 96.67 % -> Average:85.60 \n",
      "Iteration: 162 -> Best Accuracy: 96.67 % -> Average:85.60 \n",
      "Iteration: 163 -> Best Accuracy: 96.67 % -> Average:86.29 \n",
      "Iteration: 164 -> Best Accuracy: 96.67 % -> Average:88.78 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 165 -> Best Accuracy: 96.67 % -> Average:35.22 \n",
      "Iteration: 166 -> Best Accuracy: 96.67 % -> Average:52.41 \n",
      "Iteration: 167 -> Best Accuracy: 96.67 % -> Average:60.61 \n",
      "Iteration: 168 -> Best Accuracy: 96.67 % -> Average:69.40 \n",
      "Iteration: 169 -> Best Accuracy: 96.67 % -> Average:69.80 \n",
      "Iteration: 170 -> Best Accuracy: 96.67 % -> Average:71.07 \n",
      "Iteration: 171 -> Best Accuracy: 96.67 % -> Average:73.09 \n",
      "Iteration: 172 -> Best Accuracy: 96.67 % -> Average:75.27 \n",
      "Iteration: 173 -> Best Accuracy: 96.67 % -> Average:79.62 \n",
      "Iteration: 174 -> Best Accuracy: 96.67 % -> Average:81.36 \n",
      "Iteration: 175 -> Best Accuracy: 96.67 % -> Average:83.58 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 176 -> Best Accuracy: 96.67 % -> Average:47.17 \n",
      "Iteration: 177 -> Best Accuracy: 96.67 % -> Average:61.55 \n",
      "Iteration: 178 -> Best Accuracy: 96.67 % -> Average:72.84 \n",
      "Iteration: 179 -> Best Accuracy: 96.67 % -> Average:75.04 \n",
      "Iteration: 180 -> Best Accuracy: 96.67 % -> Average:78.07 \n",
      "Iteration: 181 -> Best Accuracy: 96.67 % -> Average:84.78 \n",
      "Iteration: 182 -> Best Accuracy: 96.67 % -> Average:85.56 \n",
      "Iteration: 183 -> Best Accuracy: 96.67 % -> Average:88.16 \n",
      "Iteration: 184 -> Best Accuracy: 96.67 % -> Average:88.20 \n",
      "Iteration: 185 -> Best Accuracy: 96.67 % -> Average:89.02 \n",
      "Iteration: 186 -> Best Accuracy: 96.67 % -> Average:89.82 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 187 -> Best Accuracy: 96.67 % -> Average:44.85 \n",
      "Iteration: 188 -> Best Accuracy: 96.67 % -> Average:64.06 \n",
      "Iteration: 189 -> Best Accuracy: 96.67 % -> Average:69.82 \n",
      "Iteration: 190 -> Best Accuracy: 96.67 % -> Average:73.29 \n",
      "Iteration: 191 -> Best Accuracy: 96.67 % -> Average:77.91 \n",
      "Iteration: 192 -> Best Accuracy: 96.67 % -> Average:78.78 \n",
      "Iteration: 193 -> Best Accuracy: 96.67 % -> Average:80.29 \n",
      "Iteration: 194 -> Best Accuracy: 96.67 % -> Average:81.07 \n",
      "Iteration: 195 -> Best Accuracy: 96.67 % -> Average:81.31 \n",
      "Iteration: 196 -> Best Accuracy: 96.67 % -> Average:81.49 \n",
      "Iteration: 197 -> Best Accuracy: 96.67 % -> Average:81.56 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 198 -> Best Accuracy: 96.67 % -> Average:41.11 \n",
      "Iteration: 199 -> Best Accuracy: 96.67 % -> Average:62.58 \n",
      "Iteration: 200 -> Best Accuracy: 96.67 % -> Average:68.49 \n",
      "Iteration: 201 -> Best Accuracy: 96.67 % -> Average:71.96 \n",
      "Iteration: 202 -> Best Accuracy: 96.67 % -> Average:73.20 \n",
      "Iteration: 203 -> Best Accuracy: 96.67 % -> Average:75.20 \n",
      "Iteration: 204 -> Best Accuracy: 96.67 % -> Average:77.49 \n",
      "Iteration: 205 -> Best Accuracy: 96.67 % -> Average:78.47 \n",
      "Iteration: 206 -> Best Accuracy: 96.67 % -> Average:79.44 \n",
      "Iteration: 207 -> Best Accuracy: 96.67 % -> Average:80.11 \n",
      "Iteration: 208 -> Best Accuracy: 96.67 % -> Average:81.07 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 209 -> Best Accuracy: 96.67 % -> Average:43.45 \n",
      "Iteration: 210 -> Best Accuracy: 96.67 % -> Average:62.47 \n",
      "Iteration: 211 -> Best Accuracy: 96.67 % -> Average:66.80 \n",
      "Iteration: 212 -> Best Accuracy: 96.67 % -> Average:69.00 \n",
      "Iteration: 213 -> Best Accuracy: 96.67 % -> Average:69.71 \n",
      "Iteration: 214 -> Best Accuracy: 96.67 % -> Average:71.93 \n",
      "Iteration: 215 -> Best Accuracy: 96.67 % -> Average:74.53 \n",
      "Iteration: 216 -> Best Accuracy: 96.67 % -> Average:77.04 \n",
      "Iteration: 217 -> Best Accuracy: 96.67 % -> Average:80.16 \n",
      "Iteration: 218 -> Best Accuracy: 96.67 % -> Average:81.20 \n",
      "Iteration: 219 -> Best Accuracy: 96.67 % -> Average:81.33 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 220 -> Best Accuracy: 96.67 % -> Average:49.61 \n",
      "Iteration: 221 -> Best Accuracy: 96.67 % -> Average:65.27 \n",
      "Iteration: 222 -> Best Accuracy: 96.67 % -> Average:70.22 \n",
      "Iteration: 223 -> Best Accuracy: 96.67 % -> Average:73.13 \n",
      "Iteration: 224 -> Best Accuracy: 96.67 % -> Average:76.60 \n",
      "Iteration: 225 -> Best Accuracy: 96.67 % -> Average:78.49 \n",
      "Iteration: 226 -> Best Accuracy: 96.67 % -> Average:79.44 \n",
      "Iteration: 227 -> Best Accuracy: 96.67 % -> Average:81.73 \n",
      "Iteration: 228 -> Best Accuracy: 96.67 % -> Average:83.78 \n",
      "Iteration: 229 -> Best Accuracy: 96.67 % -> Average:86.36 \n",
      "Iteration: 230 -> Best Accuracy: 96.67 % -> Average:88.20 \n",
      "Restarting population due to stalling for 10 iterations...\n",
      "Iteration: 231 -> Best Accuracy: 96.67 % -> Average:44.69 \n",
      "Iteration: 232 -> Best Accuracy: 96.67 % -> Average:65.64 \n",
      "Iteration: 233 -> Best Accuracy: 96.67 % -> Average:69.10 \n",
      "Iteration: 234 -> Best Accuracy: 96.67 % -> Average:70.99 \n",
      "Iteration: 235 -> Best Accuracy: 96.67 % -> Average:74.02 \n",
      "Iteration: 236 -> Best Accuracy: 96.67 % -> Average:76.13 \n",
      "Iteration: 237 -> Best Accuracy: 96.67 % -> Average:77.80 \n",
      "Iteration: 238 -> Best Accuracy: 96.67 % -> Average:78.69 \n",
      "Iteration: 239 -> Best Accuracy: 96.67 % -> Average:80.82 \n",
      "Iteration: 240 -> Best Accuracy: 96.67 % -> Average:81.53 \n",
      "5.274717621008555\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "population,best_solution,best_acc, history = differential_evolution(30)\n",
    "end_time = time.time()\n",
    "print((end_time - start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "best",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240
         ],
         "y": [
          66,
          66,
          66,
          66.66666666666666,
          66.66666666666666,
          66.66666666666666,
          66.66666666666666,
          69.33333333333334,
          69.33333333333334,
          69.33333333333334,
          69.33333333333334,
          69.33333333333334,
          69.33333333333334,
          69.33333333333334,
          69.33333333333334,
          69.33333333333334,
          69.33333333333334,
          69.33333333333334,
          84.66666666666667,
          84.66666666666667,
          84.66666666666667,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          95.33333333333334,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667
         ]
        },
        {
         "mode": "lines",
         "name": "average",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240
         ],
         "y": [
          1.6165206734550928,
          2.0913420641247815,
          6.5113876537399396,
          31.472918315621307,
          41.83506033340582,
          43.844444444444434,
          48.42222222222221,
          51.53333333333332,
          51.711111111111094,
          53.999999999999986,
          56.93333333333332,
          57.99999999999999,
          60.06666666666667,
          62.22222222222222,
          62.31111111111111,
          62.31111111111111,
          63.86666666666667,
          63.86666666666667,
          33.67687156616833,
          44.862369129612,
          49.26524304208803,
          53.309687486532475,
          56.53262152104402,
          60.62222222222223,
          60.93333333333333,
          61.955555555555556,
          62.222222222222214,
          62.222222222222214,
          62.222222222222214,
          62.93333333333332,
          63.888888888888886,
          64.06666666666666,
          41.2775729420356,
          56.402278648273146,
          60.24444444444445,
          61.666666666666664,
          63.6,
          67.77777777777777,
          69.44444444444444,
          70.48888888888888,
          70.88888888888889,
          71.48888888888888,
          72.9111111111111,
          40.61489014808401,
          55.81070414335805,
          61.69109100322768,
          63.37777777777777,
          65.04444444444444,
          67.97777777777779,
          71.75555555555556,
          72.97777777777779,
          72.97777777777779,
          73.2888888888889,
          73.42222222222223,
          42.876623596096145,
          61.68553076441348,
          68.91111111111111,
          71.62222222222223,
          73.84444444444445,
          74.68888888888888,
          75.84444444444445,
          76.1111111111111,
          77.57777777777777,
          77.79999999999998,
          78.3111111111111,
          48.58267886283362,
          61.02222222222221,
          65.44444444444443,
          68.88888888888889,
          73.82222222222222,
          73.88888888888889,
          75.28888888888888,
          75.84444444444445,
          76.33333333333331,
          77.1111111111111,
          77.35555555555554,
          46.044340507011405,
          61.24687442560101,
          66.62222222222222,
          67.95555555555556,
          73.66666666666669,
          73.66666666666669,
          74.5777777777778,
          76.82222222222224,
          77.66666666666669,
          78.37777777777778,
          80,
          48.91791047533066,
          62.99999999999999,
          65.75555555555556,
          70.64444444444445,
          75.3777777777778,
          76.35555555555557,
          76.60000000000001,
          77.80000000000003,
          77.91111111111113,
          78.26666666666668,
          78.86666666666669,
          47.4745616846978,
          65.63617898350702,
          70.73333333333335,
          75.31111111111112,
          76.22222222222223,
          78.62222222222222,
          79.77777777777777,
          81.75555555555555,
          82.37777777777777,
          84.6888888888889,
          85.26666666666667,
          49.21103025755148,
          59.288888888888906,
          63.088888888888896,
          67.06666666666669,
          72.24444444444447,
          73.42222222222223,
          74.4,
          74.4,
          74.46666666666667,
          75.66666666666667,
          76.22222222222221,
          50.53480877484135,
          73.13333333333334,
          76.68888888888888,
          81.2,
          83.06666666666668,
          85.4,
          85.82222222222224,
          86.80000000000001,
          88.46666666666668,
          90.17777777777779,
          90.68888888888888,
          41.191512597474,
          68.29113596233664,
          72.48888888888888,
          76.24444444444447,
          78.22222222222223,
          79.5777777777778,
          81.15555555555557,
          82.84444444444446,
          84.64444444444446,
          85.71111111111114,
          86.35555555555558,
          49.97123618844968,
          67.51111111111112,
          70.24444444444445,
          73.80000000000001,
          75.55555555555557,
          78.93333333333334,
          81.1111111111111,
          81.26666666666667,
          83.26666666666667,
          83.62222222222222,
          83.95555555555553,
          52.00733017416019,
          70.46666666666665,
          75.3111111111111,
          77.97777777777777,
          80.82222222222222,
          82.0888888888889,
          85.06666666666668,
          85.60000000000001,
          85.60000000000001,
          86.28888888888888,
          88.77777777777777,
          35.22230643265271,
          52.4082215763728,
          60.60592613183835,
          69.4,
          69.8,
          71.06666666666666,
          73.08888888888889,
          75.26666666666667,
          79.62222222222222,
          81.35555555555554,
          83.57777777777775,
          47.16973630271477,
          61.55269435100313,
          72.84444444444445,
          75.04444444444445,
          78.06666666666668,
          84.7777777777778,
          85.55555555555556,
          88.15555555555555,
          88.2,
          89.02222222222221,
          89.82222222222222,
          44.85370142604621,
          64.0638452829244,
          69.82222222222222,
          73.28888888888888,
          77.9111111111111,
          78.77777777777777,
          80.28888888888888,
          81.06666666666666,
          81.3111111111111,
          81.48888888888887,
          81.55555555555553,
          41.11400235261353,
          62.577777777777776,
          68.48888888888888,
          71.95555555555555,
          73.2,
          75.19999999999999,
          77.4888888888889,
          78.46666666666667,
          79.44444444444444,
          80.11111111111111,
          81.06666666666666,
          43.45262091817688,
          62.46624478815847,
          66.8,
          68.99999999999999,
          69.7111111111111,
          71.93333333333332,
          74.53333333333332,
          77.04444444444445,
          80.15555555555557,
          81.2,
          81.33333333333331,
          49.61119223256262,
          65.26666666666667,
          70.22222222222221,
          73.13333333333331,
          76.6,
          78.4888888888889,
          79.44444444444447,
          81.73333333333335,
          83.7777777777778,
          86.35555555555557,
          88.2,
          44.68966922351431,
          65.63715776864302,
          69.10020759715063,
          70.98909648603951,
          74.01677046524198,
          76.13333333333331,
          77.79999999999998,
          78.68888888888887,
          80.82222222222221,
          81.53333333333332
         ]
        },
        {
         "mode": "lines",
         "name": "worst",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240
         ],
         "y": [
          1.2634322535884326,
          1.3645966410055583,
          1.6171608901198415,
          8.419288297870223,
          29.051810002174737,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          34,
          34,
          38,
          38,
          38,
          41.333333333333336,
          41.333333333333336,
          1.6431808272320774,
          4.326688128113469,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          34,
          36,
          38,
          38,
          38,
          38,
          38,
          38,
          39.33333333333333,
          1.6492862449241943,
          8.73502611486099,
          26.666666666666668,
          33.33333333333333,
          33.33333333333333,
          34,
          45.33333333333333,
          45.33333333333333,
          45.33333333333333,
          45.33333333333333,
          45.33333333333333,
          0.6666666666666667,
          5.103791645289036,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          41.333333333333336,
          41.333333333333336,
          1.3172588376486853,
          3.28837617882221,
          33.33333333333333,
          33.33333333333333,
          45.33333333333333,
          45.33333333333333,
          50.66666666666667,
          50.66666666666667,
          50.66666666666667,
          50.66666666666667,
          66,
          1.7507258009517999,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          46,
          51.33333333333333,
          51.33333333333333,
          51.33333333333333,
          51.33333333333333,
          1.6139500635229593,
          5.406232768030137,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          63.33333333333333,
          1.6476467796719765,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          46,
          50.66666666666667,
          50.66666666666667,
          56.00000000000001,
          56.00000000000001,
          56.00000000000001,
          60.66666666666667,
          1.6441412720832997,
          4.418702838543764,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          53.333333333333336,
          53.333333333333336,
          1.6449327079980895,
          10,
          10,
          33.33333333333333,
          34,
          36,
          36.666666666666664,
          36.666666666666664,
          36.666666666666664,
          36.666666666666664,
          36.666666666666664,
          1.6488525253377613,
          9.333333333333334,
          33.33333333333333,
          33.33333333333333,
          34,
          34,
          34,
          52.666666666666664,
          62,
          62,
          70.66666666666667,
          0.6666666666666667,
          3.4007455367657076,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          59.333333333333336,
          59.333333333333336,
          1.6495064685054375,
          8.666666666666668,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          34,
          34,
          34,
          1.6466842994203685,
          8,
          32,
          33.33333333333333,
          34.66666666666667,
          34.66666666666667,
          66.66666666666666,
          66.66666666666666,
          66.66666666666666,
          66.66666666666666,
          67.33333333333333,
          1.2511986027564732,
          3.1406836067764616,
          14.844450621817725,
          30,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          34,
          34.66666666666667,
          50,
          54,
          1.6496265802770218,
          4.225285802469883,
          13.333333333333334,
          13.333333333333334,
          13.333333333333334,
          33.33333333333333,
          33.33333333333333,
          46,
          46,
          46,
          46,
          1.6458189302348334,
          3.6505714217735323,
          33.33333333333333,
          33.33333333333333,
          42.66666666666667,
          42.66666666666667,
          54.666666666666664,
          55.333333333333336,
          55.333333333333336,
          55.333333333333336,
          55.333333333333336,
          1.2077785315057796,
          23.333333333333332,
          23.333333333333332,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          59.333333333333336,
          59.333333333333336,
          59.333333333333336,
          1.681310803989675,
          3.3206769780880694,
          32,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          43.333333333333336,
          43.333333333333336,
          43.333333333333336,
          1.6420985448972387,
          6,
          6,
          29.333333333333332,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          41.333333333333336,
          56.666666666666664,
          56.666666666666664,
          56.666666666666664,
          1.5785189031509608,
          3.278285768698216,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          33.33333333333333,
          35.333333333333336,
          37.333333333333336
         ]
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Accuracy Type"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Evolution of Accuracy"
        },
        "xaxis": {
         "title": {
          "text": "Iteration"
         }
        },
        "yaxis": {
         "title": {
          "text": "Accuracy"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1741 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1598 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1495 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1410 - accuracy: 0.0133\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1335 - accuracy: 0.1400\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1266 - accuracy: 0.2800\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1201 - accuracy: 0.3200\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1138 - accuracy: 0.3400\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1077 - accuracy: 0.3400\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1018 - accuracy: 0.3467\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0960 - accuracy: 0.3467\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0905 - accuracy: 0.3467\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0852 - accuracy: 0.3467\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0800 - accuracy: 0.3467\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0750 - accuracy: 0.3467\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0701 - accuracy: 0.3600\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0653 - accuracy: 0.3600\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0607 - accuracy: 0.3800\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0561 - accuracy: 0.3867\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0515 - accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0471 - accuracy: 0.4333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0428 - accuracy: 0.4467\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0386 - accuracy: 0.4533\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0344 - accuracy: 0.4800\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0304 - accuracy: 0.5133\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0264 - accuracy: 0.5600\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0225 - accuracy: 0.5867\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0186 - accuracy: 0.5933\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0149 - accuracy: 0.6133\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0112 - accuracy: 0.6333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0075 - accuracy: 0.6333\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0039 - accuracy: 0.6467\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0003 - accuracy: 0.6533\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9967 - accuracy: 0.6533\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9932 - accuracy: 0.6600\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9897 - accuracy: 0.6600\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9862 - accuracy: 0.6600\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9828 - accuracy: 0.6600\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9795 - accuracy: 0.6600\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9762 - accuracy: 0.6600\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9730 - accuracy: 0.6600\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9698 - accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9665 - accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9633 - accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9600 - accuracy: 0.6733\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9567 - accuracy: 0.6733\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9533 - accuracy: 0.6733\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9500 - accuracy: 0.6733\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9466 - accuracy: 0.6733\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9433 - accuracy: 0.6733\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9400 - accuracy: 0.6733\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9367 - accuracy: 0.6733\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9334 - accuracy: 0.6800\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9301 - accuracy: 0.6800\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9267 - accuracy: 0.6800\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9234 - accuracy: 0.6800\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9201 - accuracy: 0.6867\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9167 - accuracy: 0.6867\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9134 - accuracy: 0.6867\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.9100 - accuracy: 0.6867\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9067 - accuracy: 0.6867\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9033 - accuracy: 0.6867\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8998 - accuracy: 0.6867\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8964 - accuracy: 0.6867\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8930 - accuracy: 0.6867\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8895 - accuracy: 0.6867\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8861 - accuracy: 0.6867\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8826 - accuracy: 0.6933\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8792 - accuracy: 0.6933\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8757 - accuracy: 0.6933\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8722 - accuracy: 0.6933\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8688 - accuracy: 0.6867\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8653 - accuracy: 0.6933\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8619 - accuracy: 0.6933\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8585 - accuracy: 0.6933\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8550 - accuracy: 0.6933\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8516 - accuracy: 0.6933\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8481 - accuracy: 0.7000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8447 - accuracy: 0.7000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8412 - accuracy: 0.7000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8378 - accuracy: 0.7000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8344 - accuracy: 0.7000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8309 - accuracy: 0.7000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8275 - accuracy: 0.7000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8240 - accuracy: 0.7000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8206 - accuracy: 0.7067\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8171 - accuracy: 0.7067\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8136 - accuracy: 0.7067\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8101 - accuracy: 0.7067\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8065 - accuracy: 0.7067\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8029 - accuracy: 0.7067\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7992 - accuracy: 0.7067\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7956 - accuracy: 0.7067\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7918 - accuracy: 0.7067\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7882 - accuracy: 0.7067\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7845 - accuracy: 0.7200\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7809 - accuracy: 0.7200\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7773 - accuracy: 0.7200\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7738 - accuracy: 0.7200\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7704 - accuracy: 0.7267\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 16)                80        \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 403 (1.57 KB)\n",
      "Trainable params: 403 (1.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "\n",
    "neural_network = Sequential()\n",
    "\n",
    "# Add layers to the neural network\n",
    "neural_network.add(Dense(units=16, input_dim=4))\n",
    "neural_network.add(LeakyReLU(alpha=0.01))  # Leaky ReLU activation function\n",
    "neural_network.add(Dense(units=16))\n",
    "neural_network.add(LeakyReLU(alpha=0.01))  # Leaky ReLU activation function\n",
    "neural_network.add(Dense(units=3, activation='softmax'))  # Last layer\n",
    "\n",
    "# Compile the neural network\n",
    "neural_network.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history2 = neural_network.fit(x, y, epochs=100, batch_size=150)\n",
    "\n",
    "\n",
    "# Print the summary of the neural network\n",
    "neural_network.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Accuracy",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "y": [
          0,
          0,
          0,
          0.013333333656191826,
          0.14000000059604645,
          0.2800000011920929,
          0.3199999928474426,
          0.3400000035762787,
          0.3400000035762787,
          0.3466666638851166,
          0.3466666638851166,
          0.3466666638851166,
          0.3466666638851166,
          0.3466666638851166,
          0.3466666638851166,
          0.36000001430511475,
          0.36000001430511475,
          0.3799999952316284,
          0.3866666555404663,
          0.4000000059604645,
          0.4333333373069763,
          0.4466666579246521,
          0.4533333480358124,
          0.47999998927116394,
          0.5133333206176758,
          0.5600000023841858,
          0.5866666436195374,
          0.5933333039283752,
          0.6133333444595337,
          0.6333333253860474,
          0.6333333253860474,
          0.6466666460037231,
          0.653333306312561,
          0.653333306312561,
          0.6600000262260437,
          0.6600000262260437,
          0.6600000262260437,
          0.6600000262260437,
          0.6600000262260437,
          0.6600000262260437,
          0.6600000262260437,
          0.6666666865348816,
          0.6666666865348816,
          0.6666666865348816,
          0.6733333468437195,
          0.6733333468437195,
          0.6733333468437195,
          0.6733333468437195,
          0.6733333468437195,
          0.6733333468437195,
          0.6733333468437195,
          0.6733333468437195,
          0.6800000071525574,
          0.6800000071525574,
          0.6800000071525574,
          0.6800000071525574,
          0.6866666674613953,
          0.6866666674613953,
          0.6866666674613953,
          0.6866666674613953,
          0.6866666674613953,
          0.6866666674613953,
          0.6866666674613953,
          0.6866666674613953,
          0.6866666674613953,
          0.6866666674613953,
          0.6866666674613953,
          0.6933333277702332,
          0.6933333277702332,
          0.6933333277702332,
          0.6933333277702332,
          0.6866666674613953,
          0.6933333277702332,
          0.6933333277702332,
          0.6933333277702332,
          0.6933333277702332,
          0.6933333277702332,
          0.699999988079071,
          0.699999988079071,
          0.699999988079071,
          0.699999988079071,
          0.699999988079071,
          0.699999988079071,
          0.699999988079071,
          0.699999988079071,
          0.7066666483879089,
          0.7066666483879089,
          0.7066666483879089,
          0.7066666483879089,
          0.7066666483879089,
          0.7066666483879089,
          0.7066666483879089,
          0.7066666483879089,
          0.7066666483879089,
          0.7066666483879089,
          0.7200000286102295,
          0.7200000286102295,
          0.7200000286102295,
          0.7200000286102295,
          0.7266666889190674
         ]
        },
        {
         "name": "Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "y": [
          1.1740866899490356,
          1.1597703695297241,
          1.1494958400726318,
          1.1410012245178223,
          1.1334973573684692,
          1.126631259918213,
          1.1200528144836426,
          1.1138238906860352,
          1.1077220439910889,
          1.1018017530441284,
          1.0960445404052734,
          1.0904988050460815,
          1.0851693153381348,
          1.0800189971923828,
          1.0749973058700562,
          1.070096492767334,
          1.0653331279754639,
          1.060657024383545,
          1.0560638904571533,
          1.0515466928482056,
          1.0471203327178955,
          1.0427807569503784,
          1.0385862588882446,
          1.0344417095184326,
          1.03038489818573,
          1.0263983011245728,
          1.0224719047546387,
          1.0186338424682617,
          1.0148805379867554,
          1.0111733675003052,
          1.0075352191925049,
          1.003930687904358,
          1.0003308057785034,
          0.9967361688613892,
          0.9931804537773132,
          0.9896564483642578,
          0.9861936569213867,
          0.9827833771705627,
          0.9794644117355347,
          0.9761968851089478,
          0.9729765057563782,
          0.9697557687759399,
          0.966520369052887,
          0.9632714986801147,
          0.959964394569397,
          0.9566516876220703,
          0.9533411860466003,
          0.9499965310096741,
          0.9466416239738464,
          0.943290114402771,
          0.9399741888046265,
          0.936672568321228,
          0.9333727955818176,
          0.9300627708435059,
          0.9267297387123108,
          0.9233991503715515,
          0.9200649261474609,
          0.9167395830154419,
          0.9134082198143005,
          0.9100481271743774,
          0.90667724609375,
          0.9032530784606934,
          0.8998050093650818,
          0.8964048027992249,
          0.8929739594459534,
          0.889522910118103,
          0.8861013054847717,
          0.8826479911804199,
          0.8791621923446655,
          0.875670850276947,
          0.8722188472747803,
          0.8687629103660583,
          0.8653209209442139,
          0.8618831634521484,
          0.8584590554237366,
          0.855027437210083,
          0.8515907526016235,
          0.8481317162513733,
          0.8446817398071289,
          0.841235876083374,
          0.8377823233604431,
          0.8343520760536194,
          0.830912172794342,
          0.8274634480476379,
          0.8240231871604919,
          0.8205592036247253,
          0.8171010613441467,
          0.8136006593704224,
          0.8100652098655701,
          0.8064830899238586,
          0.8028743267059326,
          0.7992420196533203,
          0.7955520749092102,
          0.7918201088905334,
          0.788161039352417,
          0.7844955921173096,
          0.7809066772460938,
          0.7773368954658508,
          0.7738321423530579,
          0.7703573107719421
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training History"
        },
        "xaxis": {
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "title": {
          "text": "Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history2(history):\n",
    "    fig = go.Figure(data=[go.Scatter(x=list(range(1, len(history.history['accuracy']) + 1)), y=history.history['accuracy'], name='Accuracy'),\n",
    "                         go.Scatter(x=list(range(1, len(history.history['loss']) + 1)), y=history.history['loss'], name='Loss')])\n",
    "    fig.update_layout(title='Training History', xaxis_title='Epochs', yaxis_title='Value')\n",
    "    fig.show()\n",
    "# Plot the training history\n",
    "plot_history2(history2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
